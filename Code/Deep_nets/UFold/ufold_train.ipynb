{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import _pickle as pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "import pdb\n",
    "import subprocess\n",
    "\n",
    "# from FCN import FCNNet\n",
    "from Network import U_Net as FCNNet\n",
    "#from Network3 import U_Net_FP as FCNNet\n",
    "\n",
    "from ufold.utils import *\n",
    "from ufold.config import process_config\n",
    "from ufold.postprocess import postprocess_new as postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]= config.gpu\n",
    "\n",
    "d = 10 # u_net_d\n",
    "BATCH_SIZE = 1\n",
    "OUT_STEP = 100\n",
    "LOAD_MODEL = False\n",
    "data_type = \"rnastralign_all_600\"\n",
    "#model_type = config.model_type\n",
    "epoches_first = 100\n",
    "evaluate_epi = 3\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/notname/Repositories/RNA-Secondary-Structure-Prediction-with-Neuro-evolutionary-approaches/Code/Deep_nets/UFold/ufold/data_generator.py:41: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.pairs = np.array([instance[-1] for instance in self.data])\n",
      "Max seq length  600\n"
     ]
    }
   ],
   "source": [
    "# for loading data\n",
    "# loading the rna ss data, the data has been preprocessed\n",
    "# 5s data is just a demo data, which do not have pseudoknot, will generate another data having that\n",
    "from ufold.data_generator import RNASSDataGenerator, Dataset\n",
    "from ufold.data_generator import Dataset_Cut_concat_new as Dataset_FCN\n",
    "#from ufold.data_generator import Dataset_Cut_concat_new_merge as Dataset_FCN_merge\n",
    "from ufold.data_generator import Dataset_Cut_concat_new_merge_multi as Dataset_FCN_merge\n",
    "import collections\n",
    "\n",
    "RNA_SS_data = collections.namedtuple('RNA_SS_data', \n",
    "    'seq ss_label length name pairs')\n",
    "\n",
    "train_data = RNASSDataGenerator('data/', 'custom_train_set.cPickle', False)\n",
    "test_data = RNASSDataGenerator('data/', 'custom_test_set.cPickle')\n",
    "val_data = RNASSDataGenerator('data/', 'custom_test_set.cPickle')\n",
    "seq_len = train_data.data_y.shape[-2]\n",
    "print('Max seq length ', seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the pytorch interface to parallel the data generation and model training\n",
    "params = {'batch_size': BATCH_SIZE,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6,\n",
    "          'drop_last': True}\n",
    "# train_set = Dataset(train_data)\n",
    "train_set = Dataset_FCN(train_data)\n",
    "#train_set = Dataset_FCN(train_data_MXUnet)\n",
    "train_generator = data.DataLoader(train_set, **params)\n",
    "# val_set = Dataset(val_data)\n",
    "val_set = Dataset_FCN(val_data)\n",
    "val_generator = data.DataLoader(val_set, **params)\n",
    "\n",
    "# test_set = Dataset(test_data)\n",
    "test_set = Dataset_FCN(test_data)\n",
    "test_generator = data.DataLoader(test_set, **params)\n",
    "\n",
    "train_merge = Dataset_FCN_merge([train_data,test_data])\n",
    "train_merge_generator = data.DataLoader(train_merge, **params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_len =500\n",
    "\n",
    "# store the intermidiate activation\n",
    "\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_net = FCNNet(img_ch=17)\n",
    "# contact_net = nn.DataParallel(contact_net, device_ids=[3, 4])\n",
    "contact_net.to(device)\n",
    "\n",
    "# contact_net.conv1d2.register_forward_hook(get_activation('conv1d2'))\n",
    "\n",
    "#if LOAD_MODEL and os.path.isfile(model_path):\n",
    "#    print('Loading u net model...')\n",
    "#    contact_net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "\n",
    "u_optimizer = optim.Adam(contact_net.parameters())\n",
    "\n",
    "# for 5s\n",
    "# pos_weight = torch.Tensor([100]).to(device)\n",
    "# for length as 600\n",
    "pos_weight = torch.Tensor([300]).to(device)\n",
    "criterion_bce_weighted = torch.nn.BCEWithLogitsLoss(\n",
    "    pos_weight = pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select one sample from the test set and perform the evaluation\n",
    "\n",
    "def model_eval_all_test():\n",
    "    contact_net.eval()\n",
    "    result_no_train = list()\n",
    "    result_no_train_shift = list()\n",
    "    seq_lens_list = list()\n",
    "    batch_n = 0\n",
    "    for contacts, seq_embeddings, matrix_reps, seq_lens, seq_ori in test_generator:\n",
    "        if batch_n%100==0:\n",
    "            print('Batch number: ', batch_n)\n",
    "        batch_n += 1\n",
    "        contacts_batch = torch.Tensor(contacts.float()).to(device)\n",
    "        seq_embedding_batch = torch.Tensor(seq_embeddings.float()).to(device)\n",
    "        seq_ori = torch.Tensor(seq_ori.float()).to(device)\n",
    "        # matrix_reps_batch = torch.unsqueeze(\n",
    "        #     torch.Tensor(matrix_reps.float()).to(device), -1)\n",
    "\n",
    "        # state_pad = torch.zeros([matrix_reps_batch.shape[0], \n",
    "        #     seq_len, seq_len]).to(device)\n",
    "\n",
    "        # PE_batch = get_pe(seq_lens, seq_len).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            pred_contacts = contact_net(seq_embedding_batch)\n",
    "\n",
    "        # only post-processing without learning\n",
    "        u_no_train = postprocess(pred_contacts,\n",
    "            seq_ori, 0.01, 0.1, 50, 1.0, True)\n",
    "        map_no_train = (u_no_train > 0.5).float()\n",
    "        result_no_train_tmp = list(map(lambda i: evaluate_exact(map_no_train.cpu()[i],\n",
    "            contacts_batch.cpu()[i]), range(contacts_batch.shape[0])))\n",
    "        result_no_train += result_no_train_tmp\n",
    "        result_no_train_tmp_shift = list(map(lambda i: evaluate_shifted(map_no_train.cpu()[i],\n",
    "            contacts_batch.cpu()[i]), range(contacts_batch.shape[0])))\n",
    "        result_no_train_shift += result_no_train_tmp_shift\n",
    "        seq_lens_list += list(seq_lens)\n",
    "\n",
    "    nt_exact_p,nt_exact_r,nt_exact_f1 = zip(*result_no_train)\n",
    "    nt_shift_p,nt_shift_r,nt_shift_f1 = zip(*result_no_train_shift)  \n",
    "    \n",
    "    print('Average testing F1 score with pure post-processing: ', np.average(nt_exact_f1))\n",
    "\n",
    "    print('Average testing F1 score with pure post-processing allow shift: ', np.average(nt_shift_f1))\n",
    "\n",
    "    print('Average testing precision with pure post-processing: ', np.average(nt_exact_p))\n",
    "\n",
    "    print('Average testing precision with pure post-processing allow shift: ', np.average(nt_shift_p))\n",
    "\n",
    "    print('Average testing recall with pure post-processing: ', np.average(nt_exact_r))\n",
    "\n",
    "    print('Average testing recall with pure post-processing allow shift: ', np.average(nt_shift_r))\n",
    "\n",
    "    result_dict = dict()\n",
    "    result_dict['exact_p'] = nt_exact_p\n",
    "    result_dict['exact_r'] = nt_exact_r\n",
    "    result_dict['exact_f1'] = nt_exact_f1\n",
    "    result_dict['shift_p'] = nt_shift_p\n",
    "    result_dict['shift_r'] = nt_shift_r\n",
    "    result_dict['shift_f1'] = nt_shift_f1\n",
    "    result_dict['seq_lens'] = seq_lens_list\n",
    "    result_dict['exact_weighted_f1'] = np.sum(np.array(nt_exact_f1)*np.array(seq_lens_list)/np.sum(seq_lens_list))\n",
    "    result_dict['shift_weighted_f1'] = np.sum(np.array(nt_shift_f1)*np.array(seq_lens_list)/np.sum(seq_lens_list))\n",
    "\n",
    "    # with open('../results/rnastralign_short_pure_pp_evaluation_dict.pickle', 'wb') as f:\n",
    "    #     pickle.dump(result_dict, f)\n",
    "\n",
    "\n",
    "    # with open('../results/rnastralign_short_greedy_sort_evaluation_dict.pickle', 'wb') as f:\n",
    "    #     pickle.dump(result_dict, f)\n",
    "    # with open('../results/fcn_rnastralign_short_greedy_sort_evaluation_dict.pickle', 'wb') as f:\n",
    "    #     pickle.dump(result_dict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "\n",
    "def test_script():\n",
    "    print('=============test===============')\n",
    "    # model_eval()\n",
    "    model_eval_all_test()\n",
    "    # torch.save(contact_net.state_dict(), model_path + f'unet{epoch}.pt')\n",
    "    # torch.save(contact_net.module.state_dict(), model_path + f'unet{epoch}.pt')\n",
    "    print('=============end test===============')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "start training...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-68482143e84b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# contact_masks = torch.Tensor(contact_map_masks(seq_lens, seq_len)).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mpred_contacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontact_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_embedding_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m#pred_contacts = contact_net(seq_embedding_batch,seq_embedding_batch_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/RNA-Secondary-Structure-Prediction-with-Neuro-evolutionary-approaches/Code/Deep_nets/UFold/Network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUp_conv5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0md4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUp4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0md4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0md4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUp_conv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Repositories/RNA-Secondary-Structure-Prediction-with-Neuro-evolutionary-approaches/Code/Deep_nets/UFold/Network.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# test_script()\n",
    "#t1 = subprocess.getstatusoutput('awk \\'{if($1 ~ /^>/)print}\\' /data2/darren/experiment/ufold/data/rnastralign_all/rnastralign_train_no_redundant.seq.cdhit')\n",
    "#all_cdhit_names = t1[1].split('\\n')\n",
    "print('start training...')\n",
    "# There are three steps of training\n",
    "# step one: train the u net\n",
    "epoch_rec = []\n",
    "for epoch in range(epoches_first):\n",
    "    contact_net.train()\n",
    "    # num_batches = int(np.ceil(train_data.len / BATCH_SIZE))\n",
    "    # for i in range(num_batches):\n",
    "    #for contacts, seq_embeddings, matrix_reps, seq_lens, seq_ori, seq_name in train_generator:\n",
    "    for contacts, seq_embeddings, matrix_reps, seq_lens, seq_ori, seq_name in train_merge_generator:\n",
    "    #for contacts, seq_embeddings, seq_embeddings_1, matrix_reps, seq_lens, seq_ori, seq_name in train_generator:\n",
    "        # contacts, seq_embeddings, matrix_reps, seq_lens = next(iter(train_generator))\n",
    "\n",
    "        '''\n",
    "        compare_name = '>' + seq_name[0]\n",
    "        if compare_name not in all_cdhit_names:\n",
    "            continue\n",
    "        if seq_lens.cpu()[0] > 1500:\n",
    "            continue\n",
    "        '''\n",
    "        contacts_batch = torch.Tensor(contacts.float()).to(device)\n",
    "        seq_embedding_batch = torch.Tensor(seq_embeddings.float()).to(device)\n",
    "        #seq_embedding_batch_1 = torch.Tensor(seq_embeddings_1.float()).to(device)\n",
    "        # matrix_reps_batch = torch.unsqueeze(\n",
    "        #     torch.Tensor(matrix_reps.float()).to(device), -1)\n",
    "\n",
    "        # padding the states for supervised training with all 0s\n",
    "        # state_pad = torch.zeros([matrix_reps_batch.shape[0], \n",
    "        #     seq_len, seq_len]).to(device)\n",
    "\n",
    "\n",
    "        # PE_batch = get_pe(seq_lens, seq_len).float().to(device)\n",
    "        # contact_masks = torch.Tensor(contact_map_masks(seq_lens, seq_len)).to(device)\n",
    "        \n",
    "        pred_contacts = contact_net(seq_embedding_batch)\n",
    "        #pred_contacts = contact_net(seq_embedding_batch,seq_embedding_batch_1)\n",
    "\n",
    "        contact_masks = torch.zeros_like(pred_contacts)\n",
    "        contact_masks[:, :seq_lens, :seq_lens] = 1\n",
    "\n",
    "        # Compute loss\n",
    "        loss_u = criterion_bce_weighted(pred_contacts*contact_masks, contacts_batch)\n",
    "\n",
    "        # print(steps_done)\n",
    "        # if steps_done % OUT_STEP ==0:\n",
    "        #     print('Stage 1, epoch: {},step: {}, loss: {}'.format(\n",
    "        #         epoch, steps_done, loss_u))\n",
    "\n",
    "        # Optimize the model\n",
    "        u_optimizer.zero_grad()\n",
    "        loss_u.backward()\n",
    "        u_optimizer.step()\n",
    "        steps_done=steps_done+1\n",
    "\n",
    "    print('Stage 1, epoch: {}, step: {}, loss: {}'.format(\n",
    "                epoch, steps_done-1, loss_u))\n",
    "    #pdb.set_trace()\n",
    "    if epoch%evaluate_epi==0:\n",
    "        # model_eval_all_test()\n",
    "        # torch.save(contact_net.state_dict(), model_path)\n",
    "        #torch.save(contact_net.state_dict(), model_path + f'unet_bpTR0_addsimmutate_addmoresimilar_finetune{epoch}.pt')\n",
    "        if epoch > 0:\n",
    "            #torch.save(contact_net.state_dict(),  f'models_ckpt/final_model/unet_train_on_TR0_continuefrom99_{epoch}.pt')\n",
    "            #torch.save(contact_net.state_dict(),  f'models_ckpt/final_model/unet_train_on_RNAlign_restart_{epoch}.pt')\n",
    "            #torch.save(contact_net.state_dict(),  f'models_ckpt/final_model/unet_train_on_merge_alldata_{epoch}.pt')\n",
    "            #torch.save(contact_net.state_dict(),  f'models_ckpt/final_model/unet_train_on_TR0bpnewOriuseMXUnet_{epoch}.pt')\n",
    "            torch.save(contact_net.state_dict(),  f'custom_model/my_model_{epoch}.pt')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_eval_all_test()\n",
    "#torch.save(contact_net.module.state_dict(), model_path + 'unet_final.pt')\n",
    "# sys.exit()"
   ]
  }
 ]
}